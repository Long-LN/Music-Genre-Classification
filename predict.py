import sys
import pickle
import numpy as np
from audio import AudioFeature
from sklearn.metrics import balanced_accuracy_score


MODEL_PATH = "trained_model.pkl"

def multioutput_balanced_accuracy(y_true, y_pred):
    scores = []
    for i in range(y_true.shape[1]):
        scores.append(balanced_accuracy_score(y_true[:, i], y_pred[:, i]))
    return sum(scores) / len(scores)

def predict(file_path):
    try:
        with open(MODEL_PATH, "rb") as f:
            model_data = pickle.load(f)
        model, encoder_genre, encoder_mood = model_data
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i m√¥ h√¨nh: {e}")
        return

    try:
        print(f"üéµ ƒêang ph√¢n t√≠ch file: {file_path}")
        audio = AudioFeature(file_path, genre="unknown")
        audio.extract_features("mfcc", "chroma", "zcr", "spectral_contrast", "rolloff", "tempo")
    except Exception as e:
        print(f"‚ùå L·ªói khi tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng: {e}")
        return

    try:
        # GridSearchCV kh√¥ng c√≥ predict_single, ch·ªâ c√≥ predict
        # B·∫°n d√πng predict v·ªõi d·ªØ li·ªáu chu·∫©n h√≥a t·ª± ƒë·ªông b·ªüi pipeline
        y_pred = model.predict(audio.features.reshape(1, -1))  # tr·∫£ v·ªÅ 2 nh√£n c√πng l√∫c

        # y_pred l√† 2D array, m·ªói c·ªôt l√† 1 output
        genre_idx = y_pred[0, 0]
        mood_idx = y_pred[0, 1]

        genre_name = encoder_genre.inverse_transform([genre_idx])[0]
        mood_name = encoder_mood.inverse_transform([mood_idx])[0]

        print(f"üîç K·∫øt qu·∫£ d·ª± ƒëo√°n:\n   ‚û§ Th·ªÉ lo·∫°i: {genre_name}\n   ‚û§ T√¢m tr·∫°ng: {mood_name}")
    except Exception as e:
        print(f"‚ùå L·ªói khi d·ª± ƒëo√°n: {e}")

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("‚ö†Ô∏è Vui l√≤ng cung c·∫•p ƒë∆∞·ªùng d·∫´n file √¢m thanh ƒë·ªÉ d·ª± ƒëo√°n.")
        sys.exit(1)

    filepath = sys.argv[1]
    predict(filepath)
